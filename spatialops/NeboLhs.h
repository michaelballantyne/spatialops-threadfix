/* This file was generated by fulmar version 0.9.0. */

/*
 * Copyright (c) 2014 The University of Utah
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to
 * deal in the Software without restriction, including without limitation the
 * rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
 * sell copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 * IN THE SOFTWARE.
 */

#ifndef NEBO_LHS_H
#  define NEBO_LHS_H

   namespace SpatialOps {
#     ifdef __CUDACC__
         template<typename LhsType, typename RhsType>
          __global__ void gpu_assign_kernel(LhsType lhs, RhsType rhs) {
             lhs.assign(rhs);
          }
#     endif
      /* __CUDACC__ */;

      template<typename CurrentMode, typename FieldType>
       struct NeboField;
      template<typename FieldType>
       struct NeboField<Initial, FieldType> {
         public:
          FieldType typedef field_type;

          NeboField<SeqWalk, FieldType> typedef SeqWalkType;

#         ifdef FIELD_EXPRESSION_THREADS
             NeboField<Resize, FieldType> typedef ResizeType;
#         endif
          /* FIELD_EXPRESSION_THREADS */

#         ifdef __CUDACC__
             NeboField<GPUWalk, FieldType> typedef GPUWalkType;
#         endif
          /* __CUDACC__ */

          NeboField<Reduction, FieldType> typedef ReductionType;

          NeboField(FieldType f)
          : field_(f)
          {}

          inline structured::GhostData possible_ghosts(void) const {
             return field_.get_ghost_data();
          }

          template<typename RhsType>
           inline void assign(bool const useGhost, RhsType rhs) {
#             ifdef __CUDACC__
#                ifdef NEBO_GPU_TEST
                    gpu_test_assign<RhsType>(useGhost, rhs)
#                else
                    if(gpu_ready()) {
                       if(rhs.gpu_ready(gpu_device_index())) {
                          gpu_assign<RhsType>(useGhost, rhs);
                       }
                       else {
                          std::ostringstream msg;
                          msg << "Nebo error in " << "Nebo Assignment" << ":\n";
                          msg << "Left-hand side of assignment allocated on ";
                          msg << "GPU but right-hand side is not (completely) ";
                          msg << "accessible on the same GPU";
                          msg << "\n";
                          msg << "\t - " << __FILE__ << " : " << __LINE__;
                          throw(std::runtime_error(msg.str()));;
                       };
                    }
                    else {
                       if(cpu_ready()) {
                          if(rhs.cpu_ready()) {
                             cpu_assign<RhsType>(useGhost, rhs);
                          }
                          else {
                             std::ostringstream msg;
                             msg << "Nebo error in " << "Nebo Assignment" <<
                             ":\n";
                             msg << "Left-hand side of assignment allocated on ";
                             msg << "CPU but right-hand side is not ";
                             msg << "(completely) accessible on CPU";
                             msg << "\n";
                             msg << "\t - " << __FILE__ << " : " << __LINE__;
                             throw(std::runtime_error(msg.str()));;
                          };
                       }
                       else {
                          std::ostringstream msg;
                          msg << "Nebo error in " << "Nebo Assignment" << ":\n";
                          msg << "Left-hand side of assignment allocated on ";
                          msg << "unknown device - not on CPU or GPU";
                          msg << "\n";
                          msg << "\t - " << __FILE__ << " : " << __LINE__;
                          throw(std::runtime_error(msg.str()));;
                       };
                    }
#                endif
                 /* NEBO_GPU_TEST */
#             else
                 cpu_assign<RhsType>(useGhost, rhs)
#             endif
              /* __CUDACC__ */;
           }

         private:
          template<typename RhsType>
           inline void cpu_assign(bool const useGhost, RhsType rhs) {
#             ifdef FIELD_EXPRESSION_THREADS
                 if(is_thread_parallel()) {
                    thread_parallel_assign<RhsType>(useGhost, rhs);
                 }
                 else { sequential_assign<RhsType>(useGhost, rhs); }
#             else
                 sequential_assign<RhsType>(useGhost, rhs)
#             endif
              /* FIELD_EXPRESSION_THREADS */;
           }

          template<typename RhsType>
           inline void sequential_assign(bool const useGhost, RhsType rhs) {
#             ifdef NEBO_REPORT_BACKEND
                 std::cout << "Starting Nebo sequential" << std::endl
#             endif
              /* NEBO_REPORT_BACKEND */;

              structured::GhostData rhs_ghosts = calculate_valid_ghost(useGhost,
                                                                       possible_ghosts(),
                                                                       field_.boundary_info(),
                                                                       rhs.possible_ghosts());

              structured::GhostData lhs_ghosts = calculate_valid_lhs_ghost(rhs_ghosts,
                                                                           field_.boundary_info());

              init(lhs_ghosts.get_minus(), lhs_ghosts.get_plus()).assign(rhs.init(rhs_ghosts.get_minus(),
                                                                                  rhs_ghosts.get_plus(),
                                                                                  structured::
                                                                                  IntVec(0,
                                                                                         0,
                                                                                         0)));

#             ifdef NEBO_REPORT_BACKEND
                 std::cout << "Finished Nebo sequential" << std::endl
#             endif
              /* NEBO_REPORT_BACKEND */;
           }

          inline SeqWalkType init(structured::IntVec const & minus,
                                  structured::IntVec const & plus) {
             return SeqWalkType((field_.reset_valid_ghosts(structured::GhostData(minus,
                                                                                 plus)),
                                 field_));
          }

#         ifdef FIELD_EXPRESSION_THREADS
             template<typename RhsType>
              inline void thread_parallel_assign(bool const useGhost,
                                                 RhsType rhs) {
#                ifdef NEBO_REPORT_BACKEND
                    std::cout << "Starting Nebo thread parallel" << std::endl
#                endif
                 /* NEBO_REPORT_BACKEND */;

                 Semaphore semaphore(0);

                 const int thread_count = field_.get_partition_count();

                 structured::GhostData rhs_ghosts = calculate_valid_ghost(useGhost,
                                                                          possible_ghosts(),
                                                                          field_.boundary_info(),
                                                                          rhs.possible_ghosts());

                 structured::GhostData lhs_ghosts = calculate_valid_lhs_ghost(rhs_ghosts,
                                                                              field_.boundary_info());

                 typename RhsType::ResizeType typedef RhsResizeType;

                 const structured::IntVec split = nebo_find_partition(resize_ghost(field_,
                                                                                   lhs_ghosts.get_minus(),
                                                                                   lhs_ghosts.get_plus()).window_with_ghost().extent(),
                                                                      thread_count);

                 const int max = nebo_partition_count(split);

                 ResizeType new_lhs = resize(lhs_ghosts.get_minus(), lhs_ghosts.get_plus());

                 RhsResizeType new_rhs = rhs.resize(rhs_ghosts.get_minus(),
                                                    rhs_ghosts.get_plus());

                 structured::IntVec location = structured::IntVec(0, 0, 0);

                 for(int count = 0; count < max; count++) {
                    ThreadPoolFIFO::self().schedule(boost::bind(&ResizeType::
                                                                template assign<RhsResizeType>,
                                                                new_lhs,
                                                                new_rhs,
                                                                split,
                                                                location,
                                                                &semaphore));

                    location = nebo_next_partition(location, split);
                 };

                 for(int ii = 0; ii < max; ii++) { semaphore.wait(); };

#                ifdef NEBO_REPORT_BACKEND
                    std::cout << "Finished Nebo thread parallel" << std::endl
#                endif
                 /* NEBO_REPORT_BACKEND */;
              }

             inline ResizeType resize(structured::IntVec const & minus,
                                      structured::IntVec const & plus) {
                return ResizeType((field_.reset_valid_ghosts(structured::
                                                             GhostData(minus,
                                                                       plus)),
                                   field_));
             }
#         endif
          /* FIELD_EXPRESSION_THREADS */

#         ifdef __CUDACC__
             template<typename RhsType>
              inline void gpu_assign(bool const useGhost, RhsType rhs) {
#                ifdef NEBO_REPORT_BACKEND
                    std::cout << "Starting Nebo CUDA" << std::endl
#                endif
                 /* NEBO_REPORT_BACKEND */;

                 structured::GhostData rhs_ghosts = calculate_valid_ghost(useGhost,
                                                                          possible_ghosts(),
                                                                          field_.boundary_info(),
                                                                          rhs.possible_ghosts());

                 structured::GhostData lhs_ghosts = calculate_valid_lhs_ghost(rhs_ghosts,
                                                                              field_.boundary_info());

                 typename RhsType::GPUWalkType typedef RhsGPUWalkType;

                 int extent0 = field_.window_with_ghost().extent(0);

                 int extent1 = field_.window_with_ghost().extent(1);

                 int blockDim = 16;

                 int gDimX = extent0 / blockDim + ((extent0 % blockDim) > 0 ? 1
                                                   : 0);

                 int gDimY = extent1 / blockDim + ((extent1 % blockDim) > 0 ? 1
                                                   : 0);

                 dim3 dimBlock(blockDim, blockDim);

                 dim3 dimGrid(gDimX, gDimY);

#                ifndef NDEBUG
                    cudaError err;

                    if(cudaSuccess != (err = cudaStreamSynchronize(field_.get_stream())))
                    {
                       std::ostringstream msg;
                       msg << "Nebo error in " << "CUDA Kernel - before call" <<
                       ":\n";
                       msg << "	 - " << cudaGetErrorString(err);
                       msg << "\n";
                       msg << "\t - " << __FILE__ << " : " << __LINE__;
                       throw(std::runtime_error(msg.str()));;
                    }
#                endif
                 /* NDEBUG */;

                 gpu_assign_kernel<GPUWalkType, RhsGPUWalkType><<<dimGrid,
                                                                  dimBlock,
                                                                  0,
                                                                  field_.get_stream()>>>(gpu_init(lhs_ghosts.get_minus(),
                                                                                                  lhs_ghosts.get_plus()),
                                                                                         rhs.gpu_init(rhs_ghosts.get_minus(),
                                                                                                      rhs_ghosts.get_plus(),
                                                                                                      structured::
                                                                                                      IntVec(0,
                                                                                                             0,
                                                                                                             0),
                                                                                                      gpu_device_index()));

#                ifndef NDEBUG
                    if(cudaSuccess != (err = cudaStreamSynchronize(field_.get_stream())))
                    {
                       std::ostringstream msg;
                       msg << "Nebo error in " << "CUDA Kernel - after call" <<
                       ":\n";
                       msg << "	 - " << cudaGetErrorString(err);
                       msg << "\n";
                       msg << "\t - " << __FILE__ << " : " << __LINE__;
                       throw(std::runtime_error(msg.str()));;
                    }
#                endif
                 /* NDEBUG */;

#                ifdef NEBO_REPORT_BACKEND
                    std::cout << "Finished Nebo CUDA" << std::endl
#                endif
                 /* NEBO_REPORT_BACKEND */;
              }

             inline bool cpu_ready(void) const {
                return LOCAL_RAM == field_.memory_device_type();
             }

             inline bool gpu_ready(void) const {
                return EXTERNAL_CUDA_GPU == field_.memory_device_type();
             }

             inline int gpu_device_index(void) const {
                return field_.device_index();
             }

             inline GPUWalkType gpu_init(structured::IntVec const & minus,
                                         structured::IntVec const & plus) {
                return GPUWalkType((field_.reset_valid_ghosts(structured::
                                                              GhostData(minus,
                                                                        plus)),
                                    field_));
             }

#            ifdef NEBO_GPU_TEST
                template<typename RhsType>
                 inline void gpu_test_assign(bool const useGhost, RhsType rhs) {
#                   ifdef NEBO_REPORT_BACKEND
                       std::cout << "Starting Nebo CUDA with Nebo copying" <<
                       std::endl
#                   endif
                    /* NEBO_REPORT_BACKEND */;

                    rhs.gpu_prep(0);

                    if(LOCAL_RAM == field_.memory_device_type()) {
                       FieldType gpu_field(field_.window_with_ghost(),
                                           field_.boundary_info(),
                                           field_.get_valid_ghost_data(),
                                           NULL,
                                           structured::InternalStorage,
                                           EXTERNAL_CUDA_GPU,
                                           0);

                       NeboField<Initial, FieldType> gpu_lhs(gpu_field);

                       gpu_lhs.template gpu_assign<RhsType>(useGhost, rhs);

                       ema::cuda::CUDADeviceInterface & CDI = ema::cuda::
                       CUDADeviceInterface::self();

                       CDI.memcpy_from(field_.field_values(),
                                       gpu_field.field_values(EXTERNAL_CUDA_GPU,
                                                              0),
                                       field_.allocated_bytes(),
                                       0);
                    }
                    else { gpu_assign<RhsType>(useGhost, rhs); };

#                   ifdef NEBO_REPORT_BACKEND
                       std::cout << "Finished Nebo CUDA with Nebo copying" <<
                       std::endl
#                   endif
                    /* NEBO_REPORT_BACKEND */;
                 }
#            endif
             /* NEBO_GPU_TEST */
#         endif
          /* __CUDACC__ */

          FieldType field_;
      };
#     ifdef FIELD_EXPRESSION_THREADS
         template<typename FieldType>
          struct NeboField<Resize, FieldType> {
            public:
             FieldType typedef field_type;

             NeboField<SeqWalk, FieldType> typedef SeqWalkType;

             NeboField(FieldType f)
             : field_(f)
             {}

#            ifdef FIELD_EXPRESSION_THREADS
                template<typename RhsType>
                 inline void assign(RhsType const & rhs,
                                    structured::IntVec const & split,
                                    structured::IntVec const & location,
                                    Semaphore * semaphore) {
                    init(split, location).assign(rhs.init(structured::IntVec(0,
                                                                             0,
                                                                             0),
                                                          split,
                                                          location));

                    semaphore->post();
                 }
#            endif
             /* FIELD_EXPRESSION_THREADS */

            private:
             inline SeqWalkType init(structured::IntVec const & split,
                                     structured::IntVec const & location) {
                return SeqWalkType(FieldType(field_.window_with_ghost().refine(split,
                                                                               location),
                                             field_));
             }

             FieldType field_;
         }
#     endif
      /* FIELD_EXPRESSION_THREADS */;
      template<typename FieldType>
       struct NeboField<SeqWalk, FieldType> {
         public:
          FieldType typedef field_type;

          typename field_type::value_type typedef value_type;

          NeboField(FieldType f)
          : xGlob_(f.window_with_ghost().glob_dim(0)),
            yGlob_(f.window_with_ghost().glob_dim(1)),
            base_(f.field_values() + (f.window_with_ghost().offset(0) + (1 == f.window_with_ghost().extent(0)
                                                                         ? 0 : f.get_valid_ghost_data().get_minus(0)))
            + (xGlob_ * ((f.window_with_ghost().offset(1) + (1 == f.window_with_ghost().extent(1)
                                                             ? 0 : f.get_valid_ghost_data().get_minus(1)))
                         + (yGlob_ * (f.window_with_ghost().offset(2) + (1 == f.window_with_ghost().extent(2)
                                                                         ? 0 : f.get_valid_ghost_data().get_minus(2))))))),
            xLow_((1 == f.window_with_ghost().extent(0) ? 0 : -(f.get_valid_ghost_data().get_minus(0)))),
            xHigh_((1 == f.window_with_ghost().extent(0) ? 1 : f.window_with_ghost().extent(0)
                    - f.get_valid_ghost_data().get_minus(0))),
            yLow_((1 == f.window_with_ghost().extent(1) ? 0 : -(f.get_valid_ghost_data().get_minus(1)))),
            yHigh_((1 == f.window_with_ghost().extent(1) ? 1 : f.window_with_ghost().extent(1)
                    - f.get_valid_ghost_data().get_minus(1))),
            zLow_((1 == f.window_with_ghost().extent(2) ? 0 : -(f.get_valid_ghost_data().get_minus(2)))),
            zHigh_((1 == f.window_with_ghost().extent(2) ? 1 : f.window_with_ghost().extent(2)
                    - f.get_valid_ghost_data().get_minus(2)))
          {}

          template<typename RhsType>
           inline void assign(RhsType rhs) {
              for(int z = zLow_; z < zHigh_; z++) {
                 for(int y = yLow_; y < yHigh_; y++) {
                    for(int x = xLow_; x < xHigh_; x++) {
                       ref(x, y, z) = rhs.eval(x, y, z);
                    };
                 };
              };
           }

         private:
          inline value_type & ref(int const x, int const y, int const z) {
             return base_[x + xGlob_ * (y + (yGlob_ * z))];
          }

          int const xGlob_;

          int const yGlob_;

          value_type * base_;

          int const xLow_;

          int const xHigh_;

          int const yLow_;

          int const yHigh_;

          int const zLow_;

          int const zHigh_;
      };
#     ifdef __CUDACC__
         template<typename FieldType>
          struct NeboField<GPUWalk, FieldType> {
            public:
             FieldType typedef field_type;

             typename field_type::value_type typedef value_type;

             NeboField(FieldType f)
             : current_(f.field_values(EXTERNAL_CUDA_GPU, f.device_index()) + f.window_with_ghost().offset(0)
               + f.window_with_ghost().glob_dim(0) * (f.window_with_ghost().offset(1)
                                                      + (f.window_with_ghost().glob_dim(1)
                                                         * f.window_with_ghost().offset(2)))),
               location_(0),
               valid_(false),
               xLength_(f.window_with_ghost().glob_dim(0)),
               xExtent_(f.window_with_ghost().extent(0)),
               yExtent_(f.window_with_ghost().extent(1)),
               zExtent_(f.window_with_ghost().extent(2)),
               step_(xLength_ * f.window_with_ghost().glob_dim(1))
             {}

             template<typename RhsType>
              __device__ inline void assign(RhsType rhs) {
                 const int ii = blockIdx.x * blockDim.x + threadIdx.x;

                 const int jj = blockIdx.y * blockDim.y + threadIdx.y;

                 start(ii, jj);

                 rhs.start(ii, jj);

                 while(!at_end()) {
                    if(valid()) { ref() = rhs.eval(); };

                    next();

                    rhs.next();
                 };
              }

            private:
             __device__ inline bool valid(void) { return valid_; }

             __device__ inline void start(int x, int y) {
                valid_ = (x < xExtent_ && x >= 0 && y < yExtent_ && y >= 0);

                if(valid()) { location_ = 0; current_ += x + y * xLength_; };
             }

             __device__ inline void next(void) {
                current_ += step_;

                location_++;
             }

             __device__ inline bool at_end(void) {
                return location_ >= zExtent_;
             }

             __device__ inline value_type & ref(void) { return *current_; }

             value_type * current_;

             int location_;

             int valid_;

             int const xLength_;

             int const xExtent_;

             int const yExtent_;

             int const zExtent_;

             int const step_;
         }
#     endif
      /* __CUDACC__ */;
   } /* SpatialOps */

#endif
/* NEBO_LHS_H */
